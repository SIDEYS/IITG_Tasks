{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "OrHmqHxdTH94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, LeaveOneGroupOut\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "TOfZG_wKTHhq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train data to csv"
      ],
      "metadata": {
        "id": "Uzudq9s6bxeq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lrHFgDlsRQFW"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv(\"X_train.txt\", sep='\\s+', header=None)\n",
        "y_train = pd.read_csv(\"y_train.txt\", sep='\\s+', header=None)\n",
        "\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "column_names = [f\"Feature_{i+1}\" for i in range(X_train.shape[1])]\n",
        "column_names.append(\"Activity\")\n",
        "train_data.columns = column_names\n",
        "\n",
        "train_data.to_csv(\"train_data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text data to csv"
      ],
      "metadata": {
        "id": "agtE-1GBb0jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.read_csv(\"X_test.txt\", sep='\\s+', header=None)\n",
        "y_test = pd.read_csv(\"y_test.txt\", sep='\\s+', header=None)\n",
        "\n",
        "test_data = pd.concat([X_test, y_test], axis=1)\n",
        "test_data.columns = column_names\n",
        "test_data.to_csv(\"test_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "1LhcOU8Bbsy7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"train_data.csv\")"
      ],
      "metadata": {
        "id": "7YzE70hDTRI4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"test_data.csv\")"
      ],
      "metadata": {
        "id": "lPJiS_V3b6Nx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting train data into features and target\n"
      ],
      "metadata": {
        "id": "YFpkNk2NUkSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train.drop(columns=[\"Activity\"])\n",
        "y = df_train[\"Activity\"]"
      ],
      "metadata": {
        "id": "8qCqc-0jTb20"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XT = df_test.drop(columns=[\"Activity\"])\n",
        "yT = df_test[\"Activity\"]"
      ],
      "metadata": {
        "id": "QXMHTfSYcBXL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7fysmBqU4f4",
        "outputId": "119f6263-b3d9-42ec-f24d-e72778ed2ce9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7352, 561), (7352,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XT.shape, yT.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q7fUn5JcK35",
        "outputId": "c3a07470-6f89-469c-e4b5-c5109048e87e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2947, 561), (2947,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading ML models"
      ],
      "metadata": {
        "id": "pfPhGtR8VAyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=500),\n",
        "    'AdaBoost': AdaBoostClassifier(algorithm=\"SAMME\")\n",
        "}"
      ],
      "metadata": {
        "id": "ZbNouAXBUoSZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code performs K-Fold Cross Validation (with 5 splits) on the specified models to evaluate their performance. It calculates and prints the mean accuracy, precision, recall and F1 for each model using the training data"
      ],
      "metadata": {
        "id": "fVW9Rpw8Vh-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted')\n",
        "}\n",
        "\n",
        "print(\"\\nModel Performance (K-Fold Cross Validation):\")\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
        "    print(f\"{model_name} - Accuracy: {scores['test_accuracy'].mean():.4f} ± {scores['test_accuracy'].std():.4f}\")\n",
        "    print(f\"{model_name} - Precision (Weighted): {scores['test_precision'].mean():.4f} ± {scores['test_precision'].std():.4f}\")\n",
        "    print(f\"{model_name} - Recall (Weighted): {scores['test_recall'].mean():.4f} ± {scores['test_recall'].std():.4f}\")\n",
        "    print(f\"{model_name} - F1 Score (Weighted): {scores['test_f1'].mean():.4f} ± {scores['test_f1'].std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nRTf6dJZ9Qf",
        "outputId": "61a8b54c-8df4-4a85-e31b-64345c1ee322"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance (K-Fold Cross Validation):\n",
            "Random Forest - Accuracy: 0.9815 ± 0.0021\n",
            "Random Forest - Precision (Weighted): 0.9816 ± 0.0021\n",
            "Random Forest - Recall (Weighted): 0.9815 ± 0.0021\n",
            "Random Forest - F1 Score (Weighted): 0.9815 ± 0.0021\n",
            "Decision Tree - Accuracy: 0.9377 ± 0.0021\n",
            "Decision Tree - Precision (Weighted): 0.9379 ± 0.0021\n",
            "Decision Tree - Recall (Weighted): 0.9377 ± 0.0021\n",
            "Decision Tree - F1 Score (Weighted): 0.9377 ± 0.0021\n",
            "Logistic Regression - Accuracy: 0.9833 ± 0.0028\n",
            "Logistic Regression - Precision (Weighted): 0.9833 ± 0.0028\n",
            "Logistic Regression - Recall (Weighted): 0.9833 ± 0.0028\n",
            "Logistic Regression - F1 Score (Weighted): 0.9833 ± 0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost - Accuracy: 0.3547 ± 0.0046\n",
            "AdaBoost - Precision (Weighted): 0.2968 ± 0.1190\n",
            "AdaBoost - Recall (Weighted): 0.3547 ± 0.0046\n",
            "AdaBoost - F1 Score (Weighted): 0.2203 ± 0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code performs Leave-One-Group-Out Cross Validation (LOGO CV) using the provided group labels (subject_train.txt) to evaluate model performance. It calculates and prints the mean accuracy and standard deviation for each model using the training data"
      ],
      "metadata": {
        "id": "B-NtyKDfWlcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_labels = np.loadtxt('subject_train.txt')\n",
        "logo = LeaveOneGroupOut()\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted')\n",
        "}\n",
        "\n",
        "print(\"\\nModel Performance (Leave-One-Subject-Out CV):\")\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_validate(model, X, y, groups=group_labels, cv=logo, scoring=scoring)\n",
        "    print(f\"{model_name} - Accuracy: {scores['test_accuracy'].mean():.4f} ± {scores['test_accuracy'].std():.4f}\")\n",
        "    print(f\"{model_name} - Precision (Weighted): {scores['test_precision'].mean():.4f} ± {scores['test_precision'].std():.4f}\")\n",
        "    print(f\"{model_name} - Recall (Weighted): {scores['test_recall'].mean():.4f} ± {scores['test_recall'].std():.4f}\")\n",
        "    print(f\"{model_name} - F1 Score (Weighted): {scores['test_f1'].mean():.4f} ± {scores['test_f1'].std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuEKDEx_Z5z-",
        "outputId": "0776bb50-f42f-4776-9c4d-e6fb8732ae86"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance (Leave-One-Subject-Out CV):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Accuracy: 0.9113 ± 0.0791\n",
            "Random Forest - Precision (Weighted): 0.9167 ± 0.0902\n",
            "Random Forest - Recall (Weighted): 0.9113 ± 0.0791\n",
            "Random Forest - F1 Score (Weighted): 0.9025 ± 0.0938\n",
            "Decision Tree - Accuracy: 0.8516 ± 0.0902\n",
            "Decision Tree - Precision (Weighted): 0.8701 ± 0.0756\n",
            "Decision Tree - Recall (Weighted): 0.8516 ± 0.0902\n",
            "Decision Tree - F1 Score (Weighted): 0.8463 ± 0.0944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.9395 ± 0.0713\n",
            "Logistic Regression - Precision (Weighted): 0.9467 ± 0.0696\n",
            "Logistic Regression - Recall (Weighted): 0.9395 ± 0.0713\n",
            "Logistic Regression - F1 Score (Weighted): 0.9347 ± 0.0820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost - Accuracy: 0.3534 ± 0.0288\n",
            "AdaBoost - Precision (Weighted): 0.1938 ± 0.0764\n",
            "AdaBoost - Recall (Weighted): 0.3534 ± 0.0288\n",
            "AdaBoost - F1 Score (Weighted): 0.2179 ± 0.0348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code performs K-Fold Cross Validation (with 5 splits) on the specified models to evaluate their performance. It calculates and prints the mean accuracy, precision, recall and F1 for each model using the testing data"
      ],
      "metadata": {
        "id": "0XpLvad_fpsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted')\n",
        "}\n",
        "\n",
        "print(\"\\nModel Performance (K-Fold Cross Validation) on test data:\")\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_validate(model, XT, yT, cv=kfold, scoring=scoring)\n",
        "    print(f\"{model_name} - Accuracy: {scores['test_accuracy'].mean():.4f} ± {scores['test_accuracy'].std():.4f}\")\n",
        "    print(f\"{model_name} - Precision (Weighted): {scores['test_precision'].mean():.4f} ± {scores['test_precision'].std():.4f}\")\n",
        "    print(f\"{model_name} - Recall (Weighted): {scores['test_recall'].mean():.4f} ± {scores['test_recall'].std():.4f}\")\n",
        "    print(f\"{model_name} - F1 Score (Weighted): {scores['test_f1'].mean():.4f} ± {scores['test_f1'].std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iZN8ZdjfLuM",
        "outputId": "ea7bed6e-0b4f-4cc9-a7ca-e2068025b55b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance (K-Fold Cross Validation) on test data:\n",
            "Random Forest - Accuracy: 0.9851 ± 0.0077\n",
            "Random Forest - Precision (Weighted): 0.9853 ± 0.0076\n",
            "Random Forest - Recall (Weighted): 0.9851 ± 0.0077\n",
            "Random Forest - F1 Score (Weighted): 0.9851 ± 0.0077\n",
            "Decision Tree - Accuracy: 0.9325 ± 0.0114\n",
            "Decision Tree - Precision (Weighted): 0.9338 ± 0.0121\n",
            "Decision Tree - Recall (Weighted): 0.9325 ± 0.0114\n",
            "Decision Tree - F1 Score (Weighted): 0.9325 ± 0.0114\n",
            "Logistic Regression - Accuracy: 0.9834 ± 0.0092\n",
            "Logistic Regression - Precision (Weighted): 0.9837 ± 0.0089\n",
            "Logistic Regression - Recall (Weighted): 0.9834 ± 0.0092\n",
            "Logistic Regression - F1 Score (Weighted): 0.9834 ± 0.0092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost - Accuracy: 0.4021 ± 0.0361\n",
            "AdaBoost - Precision (Weighted): 0.3767 ± 0.1614\n",
            "AdaBoost - Recall (Weighted): 0.4021 ± 0.0361\n",
            "AdaBoost - F1 Score (Weighted): 0.2626 ± 0.0418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code performs Leave-One-Group-Out Cross Validation (LOGO CV) using the provided group labels (subject_train.txt) to evaluate model performance. It calculates and prints the mean accuracy and standard deviation for each model using the testing data"
      ],
      "metadata": {
        "id": "PMOrkIcrf92k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_labels = np.loadtxt('subject_test.txt')\n",
        "logo = LeaveOneGroupOut()\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, average='weighted'),\n",
        "    'recall': make_scorer(recall_score, average='weighted'),\n",
        "    'f1': make_scorer(f1_score, average='weighted')\n",
        "}\n",
        "\n",
        "print(\"\\nModel Performance (Leave-One-Subject-Out CV):\")\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_validate(model, XT, yT, groups=group_labels, cv=logo, scoring=scoring)\n",
        "    print(f\"{model_name} - Accuracy: {scores['test_accuracy'].mean():.4f} ± {scores['test_accuracy'].std():.4f}\")\n",
        "    print(f\"{model_name} - Precision (Weighted): {scores['test_precision'].mean():.4f} ± {scores['test_precision'].std():.4f}\")\n",
        "    print(f\"{model_name} - Recall (Weighted): {scores['test_recall'].mean():.4f} ± {scores['test_recall'].std():.4f}\")\n",
        "    print(f\"{model_name} - F1 Score (Weighted): {scores['test_f1'].mean():.4f} ± {scores['test_f1'].std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7VzYXmnfwWd",
        "outputId": "ac4e3289-ff17-41f2-ffde-9fa0aef030bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance (Leave-One-Subject-Out CV):\n",
            "Random Forest - Accuracy: 0.9105 ± 0.0367\n",
            "Random Forest - Precision (Weighted): 0.9260 ± 0.0245\n",
            "Random Forest - Recall (Weighted): 0.9105 ± 0.0367\n",
            "Random Forest - F1 Score (Weighted): 0.9053 ± 0.0463\n",
            "Decision Tree - Accuracy: 0.8252 ± 0.0360\n",
            "Decision Tree - Precision (Weighted): 0.8452 ± 0.0408\n",
            "Decision Tree - Recall (Weighted): 0.8252 ± 0.0360\n",
            "Decision Tree - F1 Score (Weighted): 0.8175 ± 0.0379\n",
            "Logistic Regression - Accuracy: 0.9227 ± 0.0460\n",
            "Logistic Regression - Precision (Weighted): 0.9394 ± 0.0317\n",
            "Logistic Regression - Recall (Weighted): 0.9227 ± 0.0460\n",
            "Logistic Regression - F1 Score (Weighted): 0.9204 ± 0.0477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost - Accuracy: 0.3956 ± 0.0643\n",
            "AdaBoost - Precision (Weighted): 0.1997 ± 0.0708\n",
            "AdaBoost - Recall (Weighted): 0.3956 ± 0.0643\n",
            "AdaBoost - F1 Score (Weighted): 0.2517 ± 0.0695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the models using the training data and testing it using the test data"
      ],
      "metadata": {
        "id": "_poFBNjZgR8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nModel Performance on Test Data:\")\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X, y)\n",
        "    y_pred = model.predict(XT)\n",
        "    acc = accuracy_score(yT, y_pred)\n",
        "    prec = precision_score(yT, y_pred, average='weighted')\n",
        "    rec = recall_score(yT, y_pred, average='weighted')\n",
        "    f1 = f1_score(yT, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"{model_name} -> Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyKd0FF0foY4",
        "outputId": "a74cf13b-108a-4969-fe19-eb813c050be8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance on Test Data:\n",
            "Random Forest -> Accuracy: 0.9250, Precision: 0.9260, Recall: 0.9250, F1 Score: 0.9249\n",
            "Decision Tree -> Accuracy: 0.8578, Precision: 0.8584, Recall: 0.8578, F1 Score: 0.8573\n",
            "Logistic Regression -> Accuracy: 0.9610, Precision: 0.9623, Recall: 0.9610, F1 Score: 0.9608\n",
            "AdaBoost -> Accuracy: 0.3492, Precision: 0.1548, Recall: 0.3492, F1 Score: 0.2128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}